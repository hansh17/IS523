% SCIS 2018 English manuscript (for LaTeX2e)
\documentclass[a4paper]{article}
\usepackage{Style}
\usepackage{cite}
% If you use LaTeX 2.09, delete the above two lines and remove '%' below.


\begin{document}

\section{Background}

In this section, we are going to briefly explain various materials that we would cover for our attacks. Including variants of the cache attacks we are going to discuss upon attacking the block ciphers, and also some ideas about the searchable encryption.

\subsection{Cache Attacks}

The cache attacks are one of the side channel attacks that is able to recover information about AES T-table or AES key, for even better case. There are 2 most prominent attack, which are called $PRIME+PROBE$ and $FLUSH+RELOAD$.

\subsubsection{PRIME+PROBE}

$PRIME+PROBE$ attacks first loads and occupies a cache set, a set of cache lines, with some dummy code. Then after some moment, measure the time reading data that were loaded on the target cache set. If there was any cache eviction by another process, which in this context the victim, loading would take longer duration as cache miss would occur. This attack doesn't need a shared memory between target and the hostile, but the lowest unit it can attack as a whole set.

\subsubsection{FLUSH+RELOAD}

$FLUSH+RELOAD$ attacks relies upon the inclusive property of the cache policy that is held by the Intel chips. The inclusive property of the cache is that everything on L1 cache should be also on L3 cache. Thus, whenever a cache line is loaded on L1 cache, they are also loaded on L3 cache. Likewise, when a CLFLUSH, or cache flush is called for a cache line within L1 cache, then the same line is evicted from L3 cache.\par
The basic idea of $FLUSH+RELOAD$ is both victim core and the attacker's core load same line of data or instruction from the shared memory. Then the attacker flush the shared cache line from its core. Flushed from the L1 cache, the same line is evicted from L3 cache, and also evicted from the victim's L1 cache as a cascade. Now what we have to observe is that whenever victim cache reloads the same line onto its cache, the very same line is loaded onto the L3 cache again. Meaning that when the attacker reloads the line, the reload time is shortened. This attack obviously need a shared memory between the victim and the attacker, but as an opposite to the $PRIME+PROBE$ attack, it can attack as small as a single line, giving more granuality on the attack.

\section{Attacks on the Block Ciphers and Its Applications}

The contents of the first section lalalalalalalalalalllllllllllllllllllllllllllllllll.

\subsection{Searchable Encryption Attacks}

\subsubsection{Lalalala}

\subsection{Cache Side-channel Attacks}

\section{Background}



\section{Classification}



\section{Evaluation}



\section{Conclusion}

\begin{thebibliography}{9}
\bibitem{a}
Authors, ``Title,'' {\em Journal}, Pages, etc...
\bibitem{b}
Authors, {\em Book title}, Publisher, Year, etc...

\end{thebibliography}

\end{document}
% end of file

